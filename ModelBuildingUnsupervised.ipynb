{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Application d'un modèle d'apprentissage non supervisé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie notre but était d'établir un modèle d'apprentissage non supervisé sur le contenu même du mail pour essayer de dégager des mots qui revenaient assez souvent parmis tous ces mails. \n",
    "Cela avait pour but de nous aider par la suite à établir des classes pour ensuite essayer d'entrainer des modèles pour réussir à classer ces mails dans les bonnes classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/Users/pierreperrin/Desktop/IG4/semestre7/Projet_DataScience/dataset_cleaned.csv',dtype={\"content\": str},low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On se focalise juste sur le contenu du mail donc on le charge à part dans un autre dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_content_brut=dataset['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons tout d'abord nettoyer le contenu des mails : la plus petite unité d'un texte est le mot. Nous avons donc créer une fonction pour nettoyer le texte et le convertir en une simple séquence de mots en éliminant tout ce qui n'a pas d'importance dans la compréhension d'un texte (pour un ordinateur) comme par exemple la ponctuation, les lettres majuscules, les balises HTML si c'est un contenu \"salle\" comme un mail automatique par exemple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Applies some pre-processing on the given text.\n",
    "\n",
    "    Steps :\n",
    "    - Removing HTML tags\n",
    "    - Removing punctuation\n",
    "    - Lowering text\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # remove the characters [\\], ['] and [\"]\n",
    "    text = re.sub(r\"\\\\\", \"\", text)    \n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)    \n",
    "    \n",
    "    # convert text to lowercase\n",
    "    text = text.strip().lower()\n",
    "    \n",
    "    # replace punctuation characters with spaces\n",
    "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    translate_dict = dict((c, \" \") for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-940d37f807ac>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mail_content_cleaned[i] = clean_text(str(mail_content_brut[i]))\n"
     ]
    }
   ],
   "source": [
    "mail_content_cleaned = mail_content_brut\n",
    "\n",
    "for i in range(len(mail_content_brut)):\n",
    "    mail_content_cleaned[i] = clean_text(str(mail_content_brut[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(mail_content_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise ensuite le model d'apprentissage non supervisé Kmean pour définir des clusters suivant les mots présents dans le contenu des mails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(max_iter=100, n_clusters=3, n_init=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_k = 3\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      "enron\n",
      "com\n",
      "2001\n",
      "00\n",
      "jeff\n",
      "thanks\n",
      "pm\n",
      "subject\n",
      "message\n",
      "mail\n",
      "time\n",
      "know\n",
      "sent\n",
      "2000\n",
      "10\n",
      "meeting\n",
      "11\n",
      "attached\n",
      "original\n",
      "power\n",
      "Cluster 1:\n",
      "ect\n",
      "hou\n",
      "enron\n",
      "ees\n",
      "2000\n",
      "na\n",
      "corp\n",
      "cc\n",
      "pm\n",
      "subject\n",
      "forwarded\n",
      "delainey\n",
      "david\n",
      "eric\n",
      "09\n",
      "sally\n",
      "12\n",
      "bass\n",
      "02\n",
      "11\n",
      "Cluster 2:\n",
      "20\n",
      "01\n",
      "09\n",
      "enron\n",
      "energy\n",
      "power\n",
      "california\n",
      "business\n",
      "said\n",
      "company\n",
      "management\n",
      "new\n",
      "ect\n",
      "market\n",
      "018\n",
      "2001\n",
      "global\n",
      "com\n",
      "state\n",
      "risk\n"
     ]
    }
   ],
   "source": [
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :20]:\n",
    "        print(\"%s\" % terms[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On arrive pas a dégager précisement de themes différents suivant les clusters mais cela nous informe sur les mots qui reviennent souvent dans les mails. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi on a decidé par la suite de créer d'autres variables suplémentaires à notre dataset qui representeront les thèmes auxquels se rapprochent les mails. On rajoute donc les colonnes meetings, business trip, hobbie et on regarde si chaque mail correspond à un ou plusieur de ces thèmes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on décide de garder les mots les plus pertinent pour créer des colonnes correspondant au thème du mail. Cela nous permettra d'établir des modèles de prédiction supervisés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
